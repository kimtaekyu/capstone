{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-19T19:52:40.016891Z",
     "iopub.status.busy": "2025-06-19T19:52:40.016567Z",
     "iopub.status.idle": "2025-06-19T19:52:41.739277Z",
     "shell.execute_reply": "2025-06-19T19:52:41.738448Z",
     "shell.execute_reply.started": "2025-06-19T19:52:40.016865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T05:04:00.294481Z",
     "iopub.status.busy": "2025-06-20T05:04:00.293884Z",
     "iopub.status.idle": "2025-06-20T05:11:20.326687Z",
     "shell.execute_reply": "2025-06-20T05:11:20.325752Z",
     "shell.execute_reply.started": "2025-06-20T05:04:00.294456Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:06<00:00, 88.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Training with VGG16 + Augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 454/454 [05:19<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 0.4043\n",
      "▶️ Inference and Submission...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer: 100%|██████████| 2782/2782 [01:44<00:00, 26.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ aug_submission.csv created.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# ---------- Dice Loss ----------\n",
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    prob = torch.sigmoid(pred)\n",
    "    inter = (prob * target).sum(dim=(1,2))\n",
    "    union = prob.sum(dim=(1,2)) + target.sum(dim=(1,2))\n",
    "    return 1 - ((2 * inter + smooth) / (union + smooth)).mean()\n",
    "\n",
    "# ---------- Dataset ----------\n",
    "class LaneDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.images = sorted(os.listdir(img_dir))\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.images[idx]\n",
    "        img = Image.open(os.path.join(self.img_dir, fname)).convert('RGB')\n",
    "        img_t = self.transform(img)\n",
    "        if self.mask_dir:\n",
    "            m = Image.open(os.path.join(self.mask_dir, fname)).convert('L')\n",
    "            m = m.resize((img_t.shape[2], img_t.shape[1]), Image.NEAREST)\n",
    "            mask = (np.array(m) > 127).astype(np.int64)\n",
    "            return img_t, torch.from_numpy(mask)\n",
    "        else:\n",
    "            return img_t, fname, img.size\n",
    "\n",
    "# ---------- VGG16 Segmentation Model ----------\n",
    "class VGG16Seg(nn.Module):\n",
    "    def __init__(self, n_class=2, pretrained=True):\n",
    "        super().__init__()\n",
    "        vgg = models.vgg16(pretrained=pretrained)\n",
    "        self.encoder = vgg.features\n",
    "        self.classifier = nn.Conv2d(512, n_class, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        feat = self.encoder(x)\n",
    "        out = self.classifier(feat)\n",
    "        return nn.functional.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "# ---------- RLE Encoding ----------\n",
    "def mask_to_rle(mask):\n",
    "    pixels = mask.flatten(order='F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# ---------- Main Pipeline ----------\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # Transforms with augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((512, 1024)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(0.3,0.3,0.3,0.1),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((512, 1024)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    # DataLoaders\n",
    "    train_imgs = \"lanesegmentationchallenge/train/train/frames\"\n",
    "    train_masks= \"lanesegmentationchallenge/train/train/lane-masks\"\n",
    "    test_imgs = \"lanesegmentationchallenge/test/test/frames\"\n",
    "    train_ds = LaneDataset(train_imgs, train_masks, train_transform)\n",
    "    train_ld = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=4)\n",
    "    test_ds  = LaneDataset(test_imgs, None, test_transform)\n",
    "    test_ld  = DataLoader(test_ds, batch_size=1, num_workers=2)\n",
    "    # Model, optimizer, loss\n",
    "    model = VGG16Seg().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    # Training\n",
    "    print(\"▶️ Training with VGG16 + Augmentation...\")\n",
    "    for ep in range(1):\n",
    "        model.train(); tot=0\n",
    "        for imgs, masks in tqdm(train_ld, desc=f\"Epoch {ep}\"):\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            logits = model(imgs)\n",
    "            loss = 0.5 * ce_loss(logits, masks) + 0.5 * dice_loss(logits[:,1,:,:], masks==1)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            tot += loss.item()\n",
    "        print(f\"Epoch {ep} - Loss: {tot/len(train_ld):.4f}\")\n",
    "    torch.save(model.state_dict(), 'vgg16_aug.pth')\n",
    "    # Inference & Submission\n",
    "    print(\"▶️ Inference and Submission...\")\n",
    "    model.eval(); results = []\n",
    "    os.makedirs('pred_masks', exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        for imgs, fnames, orig in tqdm(test_ld, desc='Infer'):\n",
    "            imgs = imgs.to(device)\n",
    "            out = model(imgs)\n",
    "            pred = out.argmax(1).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "            pil = Image.fromarray(pred*255)\n",
    "            pil.save(os.path.join('pred_masks', fnames[0]))\n",
    "            results.append({'filename': fnames[0], 'rle': mask_to_rle(pred)})\n",
    "    pd.DataFrame(results).to_csv('submission.csv', index=False)\n",
    "    print(\"✅ aug_submission.csv created.\")\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T21:19:03.233751Z",
     "iopub.status.busy": "2025-06-19T21:19:03.233130Z",
     "iopub.status.idle": "2025-06-19T21:22:12.921855Z",
     "shell.execute_reply": "2025-06-19T21:22:12.920860Z",
     "shell.execute_reply.started": "2025-06-19T21:19:03.233727Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ 모델 학습 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 454/454 [01:33<00:00,  4.87it/s, loss=0.2442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] 평균 손실: 0.3259\n",
      "💾 모델이 simple_cnn_model.pth로 저장되었습니다.\n",
      "🧪 submission.csv 생성 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "추론 중: 100%|██████████| 2782/2782 [01:35<00:00, 29.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ submission.csv 파일이 저장되었습니다!\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# ---------- Dice Loss 함수 정의 ----------\n",
    "# 예측과 실제 정답 간의 겹치는 정도를 측정하는 Dice Loss 함수\n",
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    pred = torch.softmax(pred, dim=1)[:, 1, :, :]  # 클래스 1에 대한 softmax 확률\n",
    "    target = (target == 1).float()                 # target도 1인 픽셀만 선택\n",
    "    intersection = (pred * target).sum(dim=(1, 2)) # 교집합\n",
    "    union = pred.sum(dim=(1, 2)) + target.sum(dim=(1, 2)) # 합집합\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "# ---------- 데이터셋 클래스 ----------\n",
    "class LaneDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir=None, transform=None):\n",
    "        self.img_dir = img_dir      # 이미지 디렉토리\n",
    "        self.mask_dir = mask_dir    # 마스크 디렉토리\n",
    "        self.images = sorted(os.listdir(img_dir))  # 이미지 파일 정렬\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        pil_img = Image.open(img_path).convert('RGB')\n",
    "        original_size = pil_img.size  # (너비, 높이)\n",
    "        image = self.transform(pil_img)\n",
    "\n",
    "        if self.mask_dir:\n",
    "            # 학습/검증 시 마스크도 함께 불러옴\n",
    "            mask_path = os.path.join(self.mask_dir, img_name)\n",
    "            mask = Image.open(mask_path).convert('L').resize((1024, 512))\n",
    "            mask = (np.array(mask) > 127).astype(np.uint8)  # 이진화\n",
    "            mask = torch.tensor(mask, dtype=torch.long)\n",
    "            return image, mask\n",
    "        else:\n",
    "            # 테스트 시 마스크 없음 → 파일명과 원본 크기 반환\n",
    "            return image, img_name, original_size\n",
    "\n",
    "# ---------- 간단한 CNN 모델 정의 ----------\n",
    "class SimpleCNNModel(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        # 인코더 (특징 추출)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        # 디코더 (업샘플링)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 128, 2, 2), nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 64, 2, 2), nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        # 클래스 분류기\n",
    "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return self.classifier(x)\n",
    "# ---\n",
    "class VGG16Seg(nn.Module):\n",
    "    def __init__(self, n_class=2, pretrained=True):\n",
    "        super().__init__()\n",
    "        vgg = models.vgg16(pretrained=pretrained)\n",
    "        self.encoder = vgg.features\n",
    "        self.classifier = nn.Conv2d(512, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifier(x)  # [B, n_class, H/32, W/32]\n",
    "        # Upsample back to input size\n",
    "        return nn.functional.interpolate(x, scale_factor=32, mode='bilinear', align_corners=False)\n",
    "# ---------- 마스크를 RLE로 인코딩하는 함수 ----------\n",
    "class RESNET16Seg(nn.Module):\n",
    "    def __init__(self, n_class=2, pretrained=True):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet18(pretrained=pretrained)\n",
    "        self.encoder = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.classifier = nn.Conv2d(512, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifier(x)  # [B, n_class, H/32, W/32]\n",
    "        # Upsample back to input size\n",
    "        return nn.functional.interpolate(x, scale_factor=32, mode='bilinear', align_corners=False)\n",
    "#--\n",
    "def mask_to_rle(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return \" \".join(map(str, runs))\n",
    "\n",
    "# ---------- 메인 함수 ----------\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 이미지 전처리 정의\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((512, 1024)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # --- 학습 시작 ---\n",
    "    train_dataset = LaneDataset(\n",
    "        \"lanesegmentationchallenge/train/train/frames\",\n",
    "        \"lanesegmentationchallenge/train/train/lane-masks\",\n",
    "        transform\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "\n",
    "    model = VGG16Seg(n_class=2).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    ce_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"▶️ 모델 학습 시작...\")\n",
    "    for epoch in range(1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        for imgs, masks in pbar:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            outputs = model(imgs)\n",
    "            ce = ce_loss_fn(outputs, masks)\n",
    "            d  = dice_loss(outputs, masks)\n",
    "            loss = 0.5 * ce + 0.5 * d  \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] 평균 손실: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"simple_cnn_model.pth\")\n",
    "    print(\"💾 모델이 simple_cnn_model.pth로 저장되었습니다.\")\n",
    "\n",
    "    # --- 테스트 이미지에 대한 추론 및 제출 파일 생성 ---\n",
    "    print(\"🧪 submission.csv 생성 시작...\")\n",
    "    test_dataset = LaneDataset(\n",
    "        \"lanesegmentationchallenge/test/test/frames\",\n",
    "        None, transform\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "    model.eval()\n",
    "\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, fnames, orig_size in tqdm(test_loader, desc=\"추론 중\"):\n",
    "            imgs = imgs.to(device)\n",
    "            output = model(imgs)\n",
    "            pred_mask = output.argmax(1).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "            pred_pil = Image.fromarray(pred_mask)\n",
    "            W, H = orig_size\n",
    "            resized_mask = pred_pil.resize((W, H), resample=Image.NEAREST)\n",
    "            binary = np.array(resized_mask) > 0\n",
    "            rle = mask_to_rle(binary)\n",
    "            results.append({'filename': fnames[0], 'rle': rle})\n",
    "\n",
    "    pd.DataFrame(results).to_csv(\"aug_submission.csv\", index=False)\n",
    "    print(\"✅ submission.csv 파일이 저장되었습니다!\")\n",
    "\n",
    "# 프로그램 실행 진입점\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12341613,
     "sourceId": 102262,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
