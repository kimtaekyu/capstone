{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":102262,"databundleVersionId":12341613,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:52:40.016567Z","iopub.execute_input":"2025-06-19T19:52:40.016891Z","iopub.status.idle":"2025-06-19T19:52:41.739277Z","shell.execute_reply.started":"2025-06-19T19:52:40.016865Z","shell.execute_reply":"2025-06-19T19:52:41.738448Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n# ---------- Dice Loss í•¨ìˆ˜ ì •ì˜ ----------\n# ì˜ˆì¸¡ê³¼ ì‹¤ì œ ì •ë‹µ ê°„ì˜ ê²¹ì¹˜ëŠ” ì •ë„ë¥¼ ì¸¡ì •í•˜ëŠ” Dice Loss í•¨ìˆ˜\ndef dice_loss(pred, target, smooth=1e-6):\n    pred = torch.softmax(pred, dim=1)[:, 1, :, :]  # í´ë˜ìŠ¤ 1ì— ëŒ€í•œ softmax í™•ë¥ \n    target = (target == 1).float()                 # targetë„ 1ì¸ í”½ì…€ë§Œ ì„ íƒ\n    intersection = (pred * target).sum(dim=(1, 2)) # êµì§‘í•©\n    union = pred.sum(dim=(1, 2)) + target.sum(dim=(1, 2)) # í•©ì§‘í•©\n    dice = (2. * intersection + smooth) / (union + smooth)\n    return 1 - dice.mean()\n\n# ---------- ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ----------\nclass LaneDataset(Dataset):\n    def __init__(self, img_dir, mask_dir=None, transform=None):\n        self.img_dir = img_dir      # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬\n        self.mask_dir = mask_dir    # ë§ˆìŠ¤í¬ ë””ë ‰í† ë¦¬\n        self.images = sorted(os.listdir(img_dir))  # ì´ë¯¸ì§€ íŒŒì¼ ì •ë ¬\n        self.transform = transform\n\n    def __len__(self): \n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n        img_path = os.path.join(self.img_dir, img_name)\n        pil_img = Image.open(img_path).convert('RGB')\n        original_size = pil_img.size  # (ë„ˆë¹„, ë†’ì´)\n        image = self.transform(pil_img)\n\n        if self.mask_dir:\n            # í•™ìŠµ/ê²€ì¦ ì‹œ ë§ˆìŠ¤í¬ë„ í•¨ê»˜ ë¶ˆëŸ¬ì˜´\n            mask_path = os.path.join(self.mask_dir, img_name)\n            mask = Image.open(mask_path).convert('L').resize((1024, 512))\n            mask = (np.array(mask) > 127).astype(np.uint8)  # ì´ì§„í™”\n            mask = torch.tensor(mask, dtype=torch.long)\n            return image, mask\n        else:\n            # í…ŒìŠ¤íŠ¸ ì‹œ ë§ˆìŠ¤í¬ ì—†ìŒ â†’ íŒŒì¼ëª…ê³¼ ì›ë³¸ í¬ê¸° ë°˜í™˜\n            return image, img_name, original_size\n\n# ---------- ê°„ë‹¨í•œ CNN ëª¨ë¸ ì •ì˜ ----------\nclass SimpleCNNModel(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n        # ì¸ì½”ë” (íŠ¹ì§• ì¶”ì¶œ)\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU()\n        )\n        # ë””ì½”ë” (ì—…ìƒ˜í”Œë§)\n        self.decoder = nn.Sequential(\n            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(128, 128, 2, 2), nn.ReLU(),\n            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(64, 64, 2, 2), nn.ReLU(),\n            nn.Conv2d(64, 32, 3, padding=1), nn.ReLU()\n        )\n        # í´ë˜ìŠ¤ ë¶„ë¥˜ê¸°\n        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return self.classifier(x)\n# ---\nclass VGG16Seg(nn.Module):\n    def __init__(self, n_class=2, pretrained=True):\n        super().__init__()\n        vgg = models.vgg16(pretrained=pretrained)\n        self.encoder = vgg.features\n        self.classifier = nn.Conv2d(512, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.classifier(x)  # [B, n_class, H/32, W/32]\n        # Upsample back to input size\n        return nn.functional.interpolate(x, scale_factor=32, mode='bilinear', align_corners=False)\n# ---------- ë§ˆìŠ¤í¬ë¥¼ RLEë¡œ ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜ ----------\ndef mask_to_rle(mask):\n    pixels = mask.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \" \".join(map(str, runs))\n\n# ---------- ë©”ì¸ í•¨ìˆ˜ ----------\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    train_transform = transforms.Compose([\n    transforms.Resize((512, 1024)),             \n    # transforms.RandomHorizontalFlip(p=0.5),      \n    transforms.ColorJitter(brightness=0.2),      \n    transforms.ToTensor(),\n])\n    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì •ì˜\n    transform = transforms.Compose([\n        transforms.Resize((512, 1024)),\n        transforms.ToTensor()\n    ])\n\n    # --- í•™ìŠµ ì‹œì‘ ---\n    train_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/train/train/frames\",\n        \"/kaggle/input/lanesegmentationchallenge/train/train/lane-masks\",\n        train_transform\n    )\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n\n    model = VGG16Seg(n_class=2).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    ce_loss_fn = nn.CrossEntropyLoss()\n\n    print(\"â–¶ï¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n    for epoch in range(5):\n        model.train()\n        total_loss = 0\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n        for imgs, masks in pbar:\n            imgs, masks = imgs.to(device), masks.to(device)\n            outputs = model(imgs)\n            ce = ce_loss_fn(outputs, masks)\n            d  = dice_loss(outputs, masks)\n            loss = 0.5 * ce + 0.5 * d  \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n        print(f\"[Epoch {epoch+1}] í‰ê·  ì†ì‹¤: {total_loss / len(train_loader):.4f}\")\n\n    torch.save(model.state_dict(), \"simple_cnn_model.pth\")\n    print(\"ğŸ’¾ ëª¨ë¸ì´ simple_cnn_model.pthë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n\n    # --- í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„± ---\n    print(\"ğŸ§ª submission.csv ìƒì„± ì‹œì‘...\")\n    test_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/test/test/frames\",\n        None, transform\n    )\n    test_loader = DataLoader(test_dataset, batch_size=1)\n    model.eval()\n\n    results = []\n    with torch.no_grad():\n        for imgs, fnames, orig_size in tqdm(test_loader, desc=\"ì¶”ë¡  ì¤‘\"):\n            imgs = imgs.to(device)\n            output = model(imgs)\n            pred_mask = output.argmax(1).squeeze(0).cpu().numpy().astype(np.uint8)\n            pred_pil = Image.fromarray(pred_mask)\n            W, H = orig_size\n            resized_mask = pred_pil.resize((W, H), resample=Image.NEAREST)\n            binary = np.array(resized_mask) > 0\n            rle = mask_to_rle(binary)\n            results.append({'filename': fnames[0], 'rle': rle})\n\n    pd.DataFrame(results).to_csv(\"jitter_submission.csv\", index=False)\n    print(\"âœ… submission.csv íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n\n# í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì§„ì…ì \nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T11:09:33.726202Z","iopub.execute_input":"2025-06-20T11:09:33.726508Z","iopub.status.idle":"2025-06-20T11:38:38.317804Z","shell.execute_reply.started":"2025-06-20T11:09:33.726478Z","shell.execute_reply":"2025-06-20T11:38:38.316860Z"}},"outputs":[{"name":"stdout","text":"â–¶ï¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:17<00:00,  1.43it/s, loss=0.3128]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] í‰ê·  ì†ì‹¤: 0.3114\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:18<00:00,  1.43it/s, loss=0.2221]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] í‰ê·  ì†ì‹¤: 0.2571\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:17<00:00,  1.43it/s, loss=0.2216]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] í‰ê·  ì†ì‹¤: 0.2459\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:17<00:00,  1.43it/s, loss=0.2267]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] í‰ê·  ì†ì‹¤: 0.2391\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:17<00:00,  1.43it/s, loss=0.2268]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] í‰ê·  ì†ì‹¤: 0.2347\nğŸ’¾ ëª¨ë¸ì´ simple_cnn_model.pthë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\nğŸ§ª submission.csv ìƒì„± ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"ì¶”ë¡  ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2782/2782 [02:32<00:00, 18.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… submission.csv íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:48:03.848411Z","iopub.execute_input":"2025-06-19T19:48:03.848765Z","iopub.status.idle":"2025-06-19T19:48:03.854041Z","shell.execute_reply.started":"2025-06-19T19:48:03.848722Z","shell.execute_reply":"2025-06-19T19:48:03.853235Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n# ---------- Dice Loss í•¨ìˆ˜ ì •ì˜ ----------\n# ì˜ˆì¸¡ê³¼ ì‹¤ì œ ì •ë‹µ ê°„ì˜ ê²¹ì¹˜ëŠ” ì •ë„ë¥¼ ì¸¡ì •í•˜ëŠ” Dice Loss í•¨ìˆ˜\ndef dice_loss(pred, target, smooth=1e-6):\n    pred = torch.softmax(pred, dim=1)[:, 1, :, :]  # í´ë˜ìŠ¤ 1ì— ëŒ€í•œ softmax í™•ë¥ \n    target = (target == 1).float()                 # targetë„ 1ì¸ í”½ì…€ë§Œ ì„ íƒ\n    intersection = (pred * target).sum(dim=(1, 2)) # êµì§‘í•©\n    union = pred.sum(dim=(1, 2)) + target.sum(dim=(1, 2)) # í•©ì§‘í•©\n    dice = (2. * intersection + smooth) / (union + smooth)\n    return 1 - dice.mean()\n\n# ---------- ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ----------\nclass LaneDataset(Dataset):\n    def __init__(self, img_dir, mask_dir=None, transform=None):\n        self.img_dir = img_dir      # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬\n        self.mask_dir = mask_dir    # ë§ˆìŠ¤í¬ ë””ë ‰í† ë¦¬\n        self.images = sorted(os.listdir(img_dir))  # ì´ë¯¸ì§€ íŒŒì¼ ì •ë ¬\n        self.transform = transform\n\n    def __len__(self): \n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n        img_path = os.path.join(self.img_dir, img_name)\n        pil_img = Image.open(img_path).convert('RGB')\n        original_size = pil_img.size  # (ë„ˆë¹„, ë†’ì´)\n        image = self.transform(pil_img)\n\n        if self.mask_dir:\n            # í•™ìŠµ/ê²€ì¦ ì‹œ ë§ˆìŠ¤í¬ë„ í•¨ê»˜ ë¶ˆëŸ¬ì˜´\n            mask_path = os.path.join(self.mask_dir, img_name)\n            mask = Image.open(mask_path).convert('L').resize((1024, 512))\n            mask = (np.array(mask) > 127).astype(np.uint8)  # ì´ì§„í™”\n            mask = torch.tensor(mask, dtype=torch.long)\n            return image, mask\n        else:\n            # í…ŒìŠ¤íŠ¸ ì‹œ ë§ˆìŠ¤í¬ ì—†ìŒ â†’ íŒŒì¼ëª…ê³¼ ì›ë³¸ í¬ê¸° ë°˜í™˜\n            return image, img_name, original_size\n\n# ---------- ê°„ë‹¨í•œ CNN ëª¨ë¸ ì •ì˜ ----------\nclass SimpleCNNModel(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n        # ì¸ì½”ë” (íŠ¹ì§• ì¶”ì¶œ)\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU()\n        )\n        # ë””ì½”ë” (ì—…ìƒ˜í”Œë§)\n        self.decoder = nn.Sequential(\n            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(128, 128, 2, 2), nn.ReLU(),\n            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(64, 64, 2, 2), nn.ReLU(),\n            nn.Conv2d(64, 32, 3, padding=1), nn.ReLU()\n        )\n        # í´ë˜ìŠ¤ ë¶„ë¥˜ê¸°\n        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return self.classifier(x)\n# ---\nclass VGG16Seg(nn.Module):\n    def __init__(self, n_class=2, pretrained=True):\n        super().__init__()\n        vgg = models.vgg16(pretrained=pretrained)\n        self.encoder = vgg.features\n        self.classifier = nn.Conv2d(512, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.classifier(x)  # [B, n_class, H/32, W/32]\n        # Upsample back to input size\n        return nn.functional.interpolate(x, scale_factor=32, mode='bilinear', align_corners=False)\n# ---------- ë§ˆìŠ¤í¬ë¥¼ RLEë¡œ ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜ ----------\ndef mask_to_rle(mask):\n    pixels = mask.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \" \".join(map(str, runs))\n\n# ---------- ë©”ì¸ í•¨ìˆ˜ ----------\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    train_transform = transforms.Compose([\n    transforms.Resize((512, 1024)),             \n    transforms.RandomHorizontalFlip(p=0.5),      \n    # transforms.ColorJitter(brightness=0.2),      \n    transforms.ToTensor(),\n])\n    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì •ì˜\n    transform = transforms.Compose([\n        transforms.Resize((512, 1024)),\n        transforms.ToTensor()\n    ])\n\n    # --- í•™ìŠµ ì‹œì‘ ---\n    train_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/train/train/frames\",\n        \"/kaggle/input/lanesegmentationchallenge/train/train/lane-masks\",\n        train_transform\n    )\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n\n    model = VGG16Seg(n_class=2).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    ce_loss_fn = nn.CrossEntropyLoss()\n\n    print(\"â–¶ï¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n    for epoch in range(5):\n        model.train()\n        total_loss = 0\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n        for imgs, masks in pbar:\n            imgs, masks = imgs.to(device), masks.to(device)\n            outputs = model(imgs)\n            ce = ce_loss_fn(outputs, masks)\n            d  = dice_loss(outputs, masks)\n            loss = 0.5 * ce + 0.5 * d  \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n        print(f\"[Epoch {epoch+1}] í‰ê·  ì†ì‹¤: {total_loss / len(train_loader):.4f}\")\n\n    torch.save(model.state_dict(), \"simple_cnn_model.pth\")\n    print(\"ğŸ’¾ ëª¨ë¸ì´ simple_cnn_model.pthë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n\n    # --- í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„± ---\n    print(\"ğŸ§ª submission.csv ìƒì„± ì‹œì‘...\")\n    test_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/test/test/frames\",\n        None, transform\n    )\n    test_loader = DataLoader(test_dataset, batch_size=1)\n    model.eval()\n\n    results = []\n    with torch.no_grad():\n        for imgs, fnames, orig_size in tqdm(test_loader, desc=\"ì¶”ë¡  ì¤‘\"):\n            imgs = imgs.to(device)\n            output = model(imgs)\n            pred_mask = output.argmax(1).squeeze(0).cpu().numpy().astype(np.uint8)\n            pred_pil = Image.fromarray(pred_mask)\n            W, H = orig_size\n            resized_mask = pred_pil.resize((W, H), resample=Image.NEAREST)\n            binary = np.array(resized_mask) > 0\n            rle = mask_to_rle(binary)\n            results.append({'filename': fnames[0], 'rle': rle})\n\n    pd.DataFrame(results).to_csv(\"submission.csv\", index=False)\n    print(\"âœ… submission.csv íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n\n# í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì§„ì…ì \nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T09:48:49.250535Z","iopub.execute_input":"2025-06-20T09:48:49.250829Z","iopub.status.idle":"2025-06-20T10:17:47.132131Z","shell.execute_reply.started":"2025-06-20T09:48:49.250801Z","shell.execute_reply":"2025-06-20T10:17:47.131011Z"}},"outputs":[{"name":"stdout","text":"â–¶ï¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:15<00:00,  1.44it/s, loss=0.3691]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] í‰ê·  ì†ì‹¤: 0.4292\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:16<00:00,  1.43it/s, loss=0.3573]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] í‰ê·  ì†ì‹¤: 0.3867\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:16<00:00,  1.43it/s, loss=0.3018]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] í‰ê·  ì†ì‹¤: 0.3675\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:17<00:00,  1.43it/s, loss=0.3288]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] í‰ê·  ì†ì‹¤: 0.3586\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:16<00:00,  1.43it/s, loss=0.3923]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] í‰ê·  ì†ì‹¤: 0.3497\nğŸ’¾ ëª¨ë¸ì´ simple_cnn_model.pthë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\nğŸ§ª submission.csv ìƒì„± ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"ì¶”ë¡  ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2782/2782 [02:31<00:00, 18.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… submission.csv íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n# ---------- Dice Loss í•¨ìˆ˜ ì •ì˜ ----------\n# ì˜ˆì¸¡ê³¼ ì‹¤ì œ ì •ë‹µ ê°„ì˜ ê²¹ì¹˜ëŠ” ì •ë„ë¥¼ ì¸¡ì •í•˜ëŠ” Dice Loss í•¨ìˆ˜\ndef dice_loss(pred, target, smooth=1e-6):\n    pred = torch.softmax(pred, dim=1)[:, 1, :, :]  # í´ë˜ìŠ¤ 1ì— ëŒ€í•œ softmax í™•ë¥ \n    target = (target == 1).float()                 # targetë„ 1ì¸ í”½ì…€ë§Œ ì„ íƒ\n    intersection = (pred * target).sum(dim=(1, 2)) # êµì§‘í•©\n    union = pred.sum(dim=(1, 2)) + target.sum(dim=(1, 2)) # í•©ì§‘í•©\n    dice = (2. * intersection + smooth) / (union + smooth)\n    return 1 - dice.mean()\n\n# ---------- ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ----------\nclass LaneDataset(Dataset):\n    def __init__(self, img_dir, mask_dir=None, transform=None):\n        self.img_dir = img_dir      # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬\n        self.mask_dir = mask_dir    # ë§ˆìŠ¤í¬ ë””ë ‰í† ë¦¬\n        self.images = sorted(os.listdir(img_dir))  # ì´ë¯¸ì§€ íŒŒì¼ ì •ë ¬\n        self.transform = transform\n\n    def __len__(self): \n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n        img_path = os.path.join(self.img_dir, img_name)\n        pil_img = Image.open(img_path).convert('RGB')\n        original_size = pil_img.size  # (ë„ˆë¹„, ë†’ì´)\n        image = self.transform(pil_img)\n\n        if self.mask_dir:\n            # í•™ìŠµ/ê²€ì¦ ì‹œ ë§ˆìŠ¤í¬ë„ í•¨ê»˜ ë¶ˆëŸ¬ì˜´\n            mask_path = os.path.join(self.mask_dir, img_name)\n            mask = Image.open(mask_path).convert('L').resize((1024, 512))\n            mask = (np.array(mask) > 127).astype(np.uint8)  # ì´ì§„í™”\n            mask = torch.tensor(mask, dtype=torch.long)\n            return image, mask\n        else:\n            # í…ŒìŠ¤íŠ¸ ì‹œ ë§ˆìŠ¤í¬ ì—†ìŒ â†’ íŒŒì¼ëª…ê³¼ ì›ë³¸ í¬ê¸° ë°˜í™˜\n            return image, img_name, original_size\n\n# ---------- ê°„ë‹¨í•œ CNN ëª¨ë¸ ì •ì˜ ----------\nclass SimpleCNNModel(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n        # ì¸ì½”ë” (íŠ¹ì§• ì¶”ì¶œ)\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU()\n        )\n        # ë””ì½”ë” (ì—…ìƒ˜í”Œë§)\n        self.decoder = nn.Sequential(\n            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(128, 128, 2, 2), nn.ReLU(),\n            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(64, 64, 2, 2), nn.ReLU(),\n            nn.Conv2d(64, 32, 3, padding=1), nn.ReLU()\n        )\n        # í´ë˜ìŠ¤ ë¶„ë¥˜ê¸°\n        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return self.classifier(x)\n# ---\nclass VGG16Seg(nn.Module):\n    def __init__(self, n_class=2, pretrained=True):\n        super().__init__()\n        vgg = models.vgg16(pretrained=pretrained)\n        self.encoder = vgg.features\n        self.classifier = nn.Conv2d(512, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.classifier(x)  # [B, n_class, H/32, W/32]\n        # Upsample back to input size\n        return nn.functional.interpolate(x, scale_factor=32, mode='bilinear', align_corners=False)\n# ---------- ë§ˆìŠ¤í¬ë¥¼ RLEë¡œ ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜ ----------\ndef mask_to_rle(mask):\n    pixels = mask.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \" \".join(map(str, runs))\n\n# ---------- ë©”ì¸ í•¨ìˆ˜ ----------\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    train_transform = transforms.Compose([\n    transforms.Resize((512, 1024)),                 \n    transforms.ToTensor(),\n])\n    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì •ì˜\n    transform = transforms.Compose([\n        transforms.Resize((512, 1024)),\n        transforms.ToTensor()\n    ])\n\n    # --- í•™ìŠµ ì‹œì‘ ---\n    train_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/train/train/frames\",\n        \"/kaggle/input/lanesegmentationchallenge/train/train/lane-masks\",\n        train_transform\n    )\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n\n    model = VGG16Seg(n_class=2).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    ce_loss_fn = nn.CrossEntropyLoss()\n\n    print(\"â–¶ï¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n    for epoch in range(5):\n        model.train()\n        total_loss = 0\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n        for imgs, masks in pbar:\n            imgs, masks = imgs.to(device), masks.to(device)\n            outputs = model(imgs)\n            ce = ce_loss_fn(outputs, masks)\n            d  = dice_loss(outputs, masks)\n            loss = 0.5 * ce + 0.5 * d  \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n        print(f\"[Epoch {epoch+1}] í‰ê·  ì†ì‹¤: {total_loss / len(train_loader):.4f}\")\n\n    torch.save(model.state_dict(), \"simple_cnn_model.pth\")\n    print(\"ğŸ’¾ ëª¨ë¸ì´ simple_cnn_model.pthë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n\n    # --- í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„± ---\n    print(\"ğŸ§ª submission.csv ìƒì„± ì‹œì‘...\")\n    test_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/test/test/frames\",\n        None, transform\n    )\n    test_loader = DataLoader(test_dataset, batch_size=1)\n    model.eval()\n\n    results = []\n    with torch.no_grad():\n        for imgs, fnames, orig_size in tqdm(test_loader, desc=\"ì¶”ë¡  ì¤‘\"):\n            imgs = imgs.to(device)\n            output = model(imgs)\n            pred_mask = output.argmax(1).squeeze(0).cpu().numpy().astype(np.uint8)\n            pred_pil = Image.fromarray(pred_mask)\n            W, H = orig_size\n            resized_mask = pred_pil.resize((W, H), resample=Image.NEAREST)\n            binary = np.array(resized_mask) > 0\n            rle = mask_to_rle(binary)\n            results.append({'filename': fnames[0], 'rle': rle})\n\n    pd.DataFrame(results).to_csv(\"origin_submission.csv\", index=False)\n    print(\"âœ… submission.csv íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n\n# í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì§„ì…ì \nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T10:22:22.270496Z","iopub.execute_input":"2025-06-20T10:22:22.271081Z","iopub.status.idle":"2025-06-20T10:51:24.148164Z","shell.execute_reply.started":"2025-06-20T10:22:22.271051Z","shell.execute_reply":"2025-06-20T10:51:24.147348Z"}},"outputs":[{"name":"stdout","text":"â–¶ï¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:16<00:00,  1.43it/s, loss=0.3021]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] í‰ê·  ì†ì‹¤: 0.3033\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:17<00:00,  1.43it/s, loss=0.2403]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] í‰ê·  ì†ì‹¤: 0.2557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:17<00:00,  1.43it/s, loss=0.3354]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] í‰ê·  ì†ì‹¤: 0.2448\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:17<00:00,  1.43it/s, loss=0.2162]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] í‰ê·  ì†ì‹¤: 0.2386\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 454/454 [05:17<00:00,  1.43it/s, loss=0.2365]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] í‰ê·  ì†ì‹¤: 0.2335\nğŸ’¾ ëª¨ë¸ì´ simple_cnn_model.pthë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\nğŸ§ª submission.csv ìƒì„± ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"ì¶”ë¡  ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2782/2782 [02:32<00:00, 18.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… submission.csv íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n","output_type":"stream"}],"execution_count":3}]}