{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":102262,"databundleVersionId":12341613,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:52:40.016567Z","iopub.execute_input":"2025-06-19T19:52:40.016891Z","iopub.status.idle":"2025-06-19T19:52:41.739277Z","shell.execute_reply.started":"2025-06-19T19:52:40.016865Z","shell.execute_reply":"2025-06-19T19:52:41.738448Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# 필요한 라이브러리 임포트\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n# ---------- Dice Loss 함수 정의 ----------\n# 예측과 실제 정답 간의 겹치는 정도를 측정하는 Dice Loss 함수\ndef dice_loss(pred, target, smooth=1e-6):\n    pred = torch.softmax(pred, dim=1)[:, 1, :, :]  # 클래스 1에 대한 softmax 확률\n    target = (target == 1).float()                 # target도 1인 픽셀만 선택\n    intersection = (pred * target).sum(dim=(1, 2)) # 교집합\n    union = pred.sum(dim=(1, 2)) + target.sum(dim=(1, 2)) # 합집합\n    dice = (2. * intersection + smooth) / (union + smooth)\n    return 1 - dice.mean()\n\n# ---------- 데이터셋 클래스 ----------\nclass LaneDataset(Dataset):\n    def __init__(self, img_dir, mask_dir=None, transform=None):\n        self.img_dir = img_dir      # 이미지 디렉토리\n        self.mask_dir = mask_dir    # 마스크 디렉토리\n        self.images = sorted(os.listdir(img_dir))  # 이미지 파일 정렬\n        self.transform = transform\n\n    def __len__(self): \n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n        img_path = os.path.join(self.img_dir, img_name)\n        pil_img = Image.open(img_path).convert('RGB')\n        original_size = pil_img.size  # (너비, 높이)\n        image = self.transform(pil_img)\n\n        if self.mask_dir:\n            # 학습/검증 시 마스크도 함께 불러옴\n            mask_path = os.path.join(self.mask_dir, img_name)\n            mask = Image.open(mask_path).convert('L').resize((1024, 512))\n            mask = (np.array(mask) > 127).astype(np.uint8)  # 이진화\n            mask = torch.tensor(mask, dtype=torch.long)\n            return image, mask\n        else:\n            # 테스트 시 마스크 없음 → 파일명과 원본 크기 반환\n            return image, img_name, original_size\n\n# ---------- 간단한 CNN 모델 정의 ----------\nclass SimpleCNNModel(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n        # 인코더 (특징 추출)\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU()\n        )\n        # 디코더 (업샘플링)\n        self.decoder = nn.Sequential(\n            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(128, 128, 2, 2), nn.ReLU(),\n            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(64, 64, 2, 2), nn.ReLU(),\n            nn.Conv2d(64, 32, 3, padding=1), nn.ReLU()\n        )\n        # 클래스 분류기\n        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return self.classifier(x)\n# ---\nclass VGG16Seg(nn.Module):\n    def __init__(self, n_class=2, pretrained=True):\n        super().__init__()\n        vgg = models.vgg16(pretrained=pretrained)\n        self.encoder = vgg.features\n        self.classifier = nn.Conv2d(512, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.classifier(x)  # [B, n_class, H/32, W/32]\n        # Upsample back to input size\n        return nn.functional.interpolate(x, scale_factor=32, mode='bilinear', align_corners=False)\n# ---------- 마스크를 RLE로 인코딩하는 함수 ----------\ndef mask_to_rle(mask):\n    pixels = mask.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \" \".join(map(str, runs))\n\n# ---------- 메인 함수 ----------\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    train_transform = transforms.Compose([\n    transforms.Resize((512, 1024)),             \n    # transforms.RandomHorizontalFlip(p=0.5),      \n    transforms.ColorJitter(brightness=0.2),      \n    transforms.ToTensor(),\n])\n    # 이미지 전처리 정의\n    transform = transforms.Compose([\n        transforms.Resize((512, 1024)),\n        transforms.ToTensor()\n    ])\n\n    # --- 학습 시작 ---\n    train_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/train/train/frames\",\n        \"/kaggle/input/lanesegmentationchallenge/train/train/lane-masks\",\n        train_transform\n    )\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n\n    model = VGG16Seg(n_class=2).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    ce_loss_fn = nn.CrossEntropyLoss()\n\n    print(\"▶️ 모델 학습 시작...\")\n    for epoch in range(5):\n        model.train()\n        total_loss = 0\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n        for imgs, masks in pbar:\n            imgs, masks = imgs.to(device), masks.to(device)\n            outputs = model(imgs)\n            ce = ce_loss_fn(outputs, masks)\n            d  = dice_loss(outputs, masks)\n            loss = 0.5 * ce + 0.5 * d  \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n        print(f\"[Epoch {epoch+1}] 평균 손실: {total_loss / len(train_loader):.4f}\")\n\n    torch.save(model.state_dict(), \"simple_cnn_model.pth\")\n    print(\"💾 모델이 simple_cnn_model.pth로 저장되었습니다.\")\n\n    # --- 테스트 이미지에 대한 추론 및 제출 파일 생성 ---\n    print(\"🧪 submission.csv 생성 시작...\")\n    test_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/test/test/frames\",\n        None, transform\n    )\n    test_loader = DataLoader(test_dataset, batch_size=1)\n    model.eval()\n\n    results = []\n    with torch.no_grad():\n        for imgs, fnames, orig_size in tqdm(test_loader, desc=\"추론 중\"):\n            imgs = imgs.to(device)\n            output = model(imgs)\n            pred_mask = output.argmax(1).squeeze(0).cpu().numpy().astype(np.uint8)\n            pred_pil = Image.fromarray(pred_mask)\n            W, H = orig_size\n            resized_mask = pred_pil.resize((W, H), resample=Image.NEAREST)\n            binary = np.array(resized_mask) > 0\n            rle = mask_to_rle(binary)\n            results.append({'filename': fnames[0], 'rle': rle})\n\n    pd.DataFrame(results).to_csv(\"jitter_submission.csv\", index=False)\n    print(\"✅ submission.csv 파일이 저장되었습니다!\")\n\n# 프로그램 실행 진입점\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T11:09:33.726202Z","iopub.execute_input":"2025-06-20T11:09:33.726508Z","iopub.status.idle":"2025-06-20T11:38:38.317804Z","shell.execute_reply.started":"2025-06-20T11:09:33.726478Z","shell.execute_reply":"2025-06-20T11:38:38.316860Z"}},"outputs":[{"name":"stdout","text":"▶️ 모델 학습 시작...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 454/454 [05:17<00:00,  1.43it/s, loss=0.3128]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] 평균 손실: 0.3114\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 454/454 [05:18<00:00,  1.43it/s, loss=0.2221]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] 평균 손실: 0.2571\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 454/454 [05:17<00:00,  1.43it/s, loss=0.2216]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] 평균 손실: 0.2459\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 454/454 [05:17<00:00,  1.43it/s, loss=0.2267]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] 평균 손실: 0.2391\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 454/454 [05:17<00:00,  1.43it/s, loss=0.2268]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] 평균 손실: 0.2347\n💾 모델이 simple_cnn_model.pth로 저장되었습니다.\n🧪 submission.csv 생성 시작...\n","output_type":"stream"},{"name":"stderr","text":"추론 중: 100%|██████████| 2782/2782 [02:32<00:00, 18.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"✅ submission.csv 파일이 저장되었습니다!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:48:03.848411Z","iopub.execute_input":"2025-06-19T19:48:03.848765Z","iopub.status.idle":"2025-06-19T19:48:03.854041Z","shell.execute_reply.started":"2025-06-19T19:48:03.848722Z","shell.execute_reply":"2025-06-19T19:48:03.853235Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# 필요한 라이브러리 임포트\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n# ---------- Dice Loss 함수 정의 ----------\n# 예측과 실제 정답 간의 겹치는 정도를 측정하는 Dice Loss 함수\ndef dice_loss(pred, target, smooth=1e-6):\n    pred = torch.softmax(pred, dim=1)[:, 1, :, :]  # 클래스 1에 대한 softmax 확률\n    target = (target == 1).float()                 # target도 1인 픽셀만 선택\n    intersection = (pred * target).sum(dim=(1, 2)) # 교집합\n    union = pred.sum(dim=(1, 2)) + target.sum(dim=(1, 2)) # 합집합\n    dice = (2. * intersection + smooth) / (union + smooth)\n    return 1 - dice.mean()\n\n# ---------- 데이터셋 클래스 ----------\nclass LaneDataset(Dataset):\n    def __init__(self, img_dir, mask_dir=None, transform=None):\n        self.img_dir = img_dir      # 이미지 디렉토리\n        self.mask_dir = mask_dir    # 마스크 디렉토리\n        self.images = sorted(os.listdir(img_dir))  # 이미지 파일 정렬\n        self.transform = transform\n\n    def __len__(self): \n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n        img_path = os.path.join(self.img_dir, img_name)\n        pil_img = Image.open(img_path).convert('RGB')\n        original_size = pil_img.size  # (너비, 높이)\n        image = self.transform(pil_img)\n\n        if self.mask_dir:\n            # 학습/검증 시 마스크도 함께 불러옴\n            mask_path = os.path.join(self.mask_dir, img_name)\n            mask = Image.open(mask_path).convert('L').resize((1024, 512))\n            mask = (np.array(mask) > 127).astype(np.uint8)  # 이진화\n            mask = torch.tensor(mask, dtype=torch.long)\n            return image, mask\n        else:\n            # 테스트 시 마스크 없음 → 파일명과 원본 크기 반환\n            return image, img_name, original_size\n\n# ---------- 간단한 CNN 모델 정의 ----------\nclass SimpleCNNModel(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n        # 인코더 (특징 추출)\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU()\n        )\n        # 디코더 (업샘플링)\n        self.decoder = nn.Sequential(\n            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(128, 128, 2, 2), nn.ReLU(),\n            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(64, 64, 2, 2), nn.ReLU(),\n            nn.Conv2d(64, 32, 3, padding=1), nn.ReLU()\n        )\n        # 클래스 분류기\n        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return self.classifier(x)\n# ---\nclass VGG16Seg(nn.Module):\n    def __init__(self, n_class=2, pretrained=True):\n        super().__init__()\n        vgg = models.vgg16(pretrained=pretrained)\n        self.encoder = vgg.features\n        self.classifier = nn.Conv2d(512, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.classifier(x)  # [B, n_class, H/32, W/32]\n        # Upsample back to input size\n        return nn.functional.interpolate(x, scale_factor=32, mode='bilinear', align_corners=False)\n# ---------- 마스크를 RLE로 인코딩하는 함수 ----------\ndef mask_to_rle(mask):\n    pixels = mask.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \" \".join(map(str, runs))\n\n# ---------- 메인 함수 ----------\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    train_transform = transforms.Compose([\n    transforms.Resize((512, 1024)),             \n    transforms.RandomHorizontalFlip(p=0.5),      \n    # transforms.ColorJitter(brightness=0.2),      \n    transforms.ToTensor(),\n])\n    # 이미지 전처리 정의\n    transform = transforms.Compose([\n        transforms.Resize((512, 1024)),\n        transforms.ToTensor()\n    ])\n\n    # --- 학습 시작 ---\n    train_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/train/train/frames\",\n        \"/kaggle/input/lanesegmentationchallenge/train/train/lane-masks\",\n        train_transform\n    )\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n\n    model = VGG16Seg(n_class=2).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    ce_loss_fn = nn.CrossEntropyLoss()\n\n    print(\"▶️ 모델 학습 시작...\")\n    for epoch in range(5):\n        model.train()\n        total_loss = 0\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n        for imgs, masks in pbar:\n            imgs, masks = imgs.to(device), masks.to(device)\n            outputs = model(imgs)\n            ce = ce_loss_fn(outputs, masks)\n            d  = dice_loss(outputs, masks)\n            loss = 0.5 * ce + 0.5 * d  \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n        print(f\"[Epoch {epoch+1}] 평균 손실: {total_loss / len(train_loader):.4f}\")\n\n    torch.save(model.state_dict(), \"simple_cnn_model.pth\")\n    print(\"💾 모델이 simple_cnn_model.pth로 저장되었습니다.\")\n\n    # --- 테스트 이미지에 대한 추론 및 제출 파일 생성 ---\n    print(\"🧪 submission.csv 생성 시작...\")\n    test_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/test/test/frames\",\n        None, transform\n    )\n    test_loader = DataLoader(test_dataset, batch_size=1)\n    model.eval()\n\n    results = []\n    with torch.no_grad():\n        for imgs, fnames, orig_size in tqdm(test_loader, desc=\"추론 중\"):\n            imgs = imgs.to(device)\n            output = model(imgs)\n            pred_mask = output.argmax(1).squeeze(0).cpu().numpy().astype(np.uint8)\n            pred_pil = Image.fromarray(pred_mask)\n            W, H = orig_size\n            resized_mask = pred_pil.resize((W, H), resample=Image.NEAREST)\n            binary = np.array(resized_mask) > 0\n            rle = mask_to_rle(binary)\n            results.append({'filename': fnames[0], 'rle': rle})\n\n    pd.DataFrame(results).to_csv(\"submission.csv\", index=False)\n    print(\"✅ submission.csv 파일이 저장되었습니다!\")\n\n# 프로그램 실행 진입점\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T09:48:49.250535Z","iopub.execute_input":"2025-06-20T09:48:49.250829Z","iopub.status.idle":"2025-06-20T10:17:47.132131Z","shell.execute_reply.started":"2025-06-20T09:48:49.250801Z","shell.execute_reply":"2025-06-20T10:17:47.131011Z"}},"outputs":[{"name":"stdout","text":"▶️ 모델 학습 시작...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 454/454 [05:15<00:00,  1.44it/s, loss=0.3691]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] 평균 손실: 0.4292\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 454/454 [05:16<00:00,  1.43it/s, loss=0.3573]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] 평균 손실: 0.3867\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 454/454 [05:16<00:00,  1.43it/s, loss=0.3018]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] 평균 손실: 0.3675\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 454/454 [05:17<00:00,  1.43it/s, loss=0.3288]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] 평균 손실: 0.3586\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 454/454 [05:16<00:00,  1.43it/s, loss=0.3923]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] 평균 손실: 0.3497\n💾 모델이 simple_cnn_model.pth로 저장되었습니다.\n🧪 submission.csv 생성 시작...\n","output_type":"stream"},{"name":"stderr","text":"추론 중: 100%|██████████| 2782/2782 [02:31<00:00, 18.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"✅ submission.csv 파일이 저장되었습니다!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 필요한 라이브러리 임포트\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n# ---------- Dice Loss 함수 정의 ----------\n# 예측과 실제 정답 간의 겹치는 정도를 측정하는 Dice Loss 함수\ndef dice_loss(pred, target, smooth=1e-6):\n    pred = torch.softmax(pred, dim=1)[:, 1, :, :]  # 클래스 1에 대한 softmax 확률\n    target = (target == 1).float()                 # target도 1인 픽셀만 선택\n    intersection = (pred * target).sum(dim=(1, 2)) # 교집합\n    union = pred.sum(dim=(1, 2)) + target.sum(dim=(1, 2)) # 합집합\n    dice = (2. * intersection + smooth) / (union + smooth)\n    return 1 - dice.mean()\n\n# ---------- 데이터셋 클래스 ----------\nclass LaneDataset(Dataset):\n    def __init__(self, img_dir, mask_dir=None, transform=None):\n        self.img_dir = img_dir      # 이미지 디렉토리\n        self.mask_dir = mask_dir    # 마스크 디렉토리\n        self.images = sorted(os.listdir(img_dir))  # 이미지 파일 정렬\n        self.transform = transform\n\n    def __len__(self): \n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n        img_path = os.path.join(self.img_dir, img_name)\n        pil_img = Image.open(img_path).convert('RGB')\n        original_size = pil_img.size  # (너비, 높이)\n        image = self.transform(pil_img)\n\n        if self.mask_dir:\n            # 학습/검증 시 마스크도 함께 불러옴\n            mask_path = os.path.join(self.mask_dir, img_name)\n            mask = Image.open(mask_path).convert('L').resize((1024, 512))\n            mask = (np.array(mask) > 127).astype(np.uint8)  # 이진화\n            mask = torch.tensor(mask, dtype=torch.long)\n            return image, mask\n        else:\n            # 테스트 시 마스크 없음 → 파일명과 원본 크기 반환\n            return image, img_name, original_size\n\n# ---------- 간단한 CNN 모델 정의 ----------\nclass SimpleCNNModel(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n        # 인코더 (특징 추출)\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU()\n        )\n        # 디코더 (업샘플링)\n        self.decoder = nn.Sequential(\n            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(128, 128, 2, 2), nn.ReLU(),\n            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(),\n            nn.ConvTranspose2d(64, 64, 2, 2), nn.ReLU(),\n            nn.Conv2d(64, 32, 3, padding=1), nn.ReLU()\n        )\n        # 클래스 분류기\n        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return self.classifier(x)\n# ---\nclass VGG16Seg(nn.Module):\n    def __init__(self, n_class=2, pretrained=True):\n        super().__init__()\n        vgg = models.vgg16(pretrained=pretrained)\n        self.encoder = vgg.features\n        self.classifier = nn.Conv2d(512, n_class, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.classifier(x)  # [B, n_class, H/32, W/32]\n        # Upsample back to input size\n        return nn.functional.interpolate(x, scale_factor=32, mode='bilinear', align_corners=False)\n# ---------- 마스크를 RLE로 인코딩하는 함수 ----------\ndef mask_to_rle(mask):\n    pixels = mask.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \" \".join(map(str, runs))\n\n# ---------- 메인 함수 ----------\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    train_transform = transforms.Compose([\n    transforms.Resize((512, 1024)),                 \n    transforms.ToTensor(),\n])\n    # 이미지 전처리 정의\n    transform = transforms.Compose([\n        transforms.Resize((512, 1024)),\n        transforms.ToTensor()\n    ])\n\n    # --- 학습 시작 ---\n    train_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/train/train/frames\",\n        \"/kaggle/input/lanesegmentationchallenge/train/train/lane-masks\",\n        train_transform\n    )\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n\n    model = VGG16Seg(n_class=2).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    ce_loss_fn = nn.CrossEntropyLoss()\n\n    print(\"▶️ 모델 학습 시작...\")\n    for epoch in range(5):\n        model.train()\n        total_loss = 0\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n        for imgs, masks in pbar:\n            imgs, masks = imgs.to(device), masks.to(device)\n            outputs = model(imgs)\n            ce = ce_loss_fn(outputs, masks)\n            d  = dice_loss(outputs, masks)\n            loss = 0.5 * ce + 0.5 * d  \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n        print(f\"[Epoch {epoch+1}] 평균 손실: {total_loss / len(train_loader):.4f}\")\n\n    torch.save(model.state_dict(), \"simple_cnn_model.pth\")\n    print(\"💾 모델이 simple_cnn_model.pth로 저장되었습니다.\")\n\n    # --- 테스트 이미지에 대한 추론 및 제출 파일 생성 ---\n    print(\"🧪 submission.csv 생성 시작...\")\n    test_dataset = LaneDataset(\n        \"/kaggle/input/lanesegmentationchallenge/test/test/frames\",\n        None, transform\n    )\n    test_loader = DataLoader(test_dataset, batch_size=1)\n    model.eval()\n\n    results = []\n    with torch.no_grad():\n        for imgs, fnames, orig_size in tqdm(test_loader, desc=\"추론 중\"):\n            imgs = imgs.to(device)\n            output = model(imgs)\n            pred_mask = output.argmax(1).squeeze(0).cpu().numpy().astype(np.uint8)\n            pred_pil = Image.fromarray(pred_mask)\n            W, H = orig_size\n            resized_mask = pred_pil.resize((W, H), resample=Image.NEAREST)\n            binary = np.array(resized_mask) > 0\n            rle = mask_to_rle(binary)\n            results.append({'filename': fnames[0], 'rle': rle})\n\n    pd.DataFrame(results).to_csv(\"origin_submission.csv\", index=False)\n    print(\"✅ submission.csv 파일이 저장되었습니다!\")\n\n# 프로그램 실행 진입점\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T10:22:22.270496Z","iopub.execute_input":"2025-06-20T10:22:22.271081Z","iopub.status.idle":"2025-06-20T10:51:24.148164Z","shell.execute_reply.started":"2025-06-20T10:22:22.271051Z","shell.execute_reply":"2025-06-20T10:51:24.147348Z"}},"outputs":[{"name":"stdout","text":"▶️ 모델 학습 시작...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 454/454 [05:16<00:00,  1.43it/s, loss=0.3021]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] 평균 손실: 0.3033\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 454/454 [05:17<00:00,  1.43it/s, loss=0.2403]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] 평균 손실: 0.2557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 454/454 [05:17<00:00,  1.43it/s, loss=0.3354]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] 평균 손실: 0.2448\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 454/454 [05:17<00:00,  1.43it/s, loss=0.2162]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] 평균 손실: 0.2386\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 454/454 [05:17<00:00,  1.43it/s, loss=0.2365]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] 평균 손실: 0.2335\n💾 모델이 simple_cnn_model.pth로 저장되었습니다.\n🧪 submission.csv 생성 시작...\n","output_type":"stream"},{"name":"stderr","text":"추론 중: 100%|██████████| 2782/2782 [02:32<00:00, 18.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"✅ submission.csv 파일이 저장되었습니다!\n","output_type":"stream"}],"execution_count":3}]}